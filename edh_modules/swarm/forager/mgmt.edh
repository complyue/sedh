
import * 'net'

import * 'swarm/RT'

# work definition scripts are allowed to change the inferred
# configuration at 'swarm/ENV', import it as a namespace to
# always use up-to-date artifacts living there
senv = { import (** _ ) 'swarm/ENV' }

import * './wsq'


# worksource connection, and the team of workers employed by it
export class WSC {

  method __init__ (
    forager as this.forager,
    addr as this.addr,
    hcPlanned as this.hcPlanned,
    executable as this.executable,
    workDir as this.workDir,
    workModu as this.workModu,
    priority as this.priority,
  ) {
    # headcount reserved for this worksource
    this.hcReserved = 0
    # headcount hired by the worksource, updated from the worksource,
    # as its demands changed
    this.hcEmployed = sink

    # all live worker processes by pid
    this.workers = {}

    # stop signal for this wsc
    this.stopped = sink

    # ever increasing number to track reform bumps
    this.reformNumber = sink
    this.reformNumber <- 0 # initialize to 0
  }

  method __repr__() {
    '<WorkTeamFor ' ++ this.addr ++ ' ' ++ this.workers.size ++ '/'
    ++ mre( this.hcEmployed ) ++ '/' ++ this.hcReserved
    ++ '/' ++ this.hcPlanned ++ '>'
  }

  method key() repr( this.addr )

  method engage ( hcAvailable ) {
    this.hcReserved = min( hcAvailable, this.hcPlanned )

    # artifacts should be implanted into the worksource facing, negotiator
    # module
    namespace nego'arts ( wsc = this ) export {
      wsc = wsc # for it to be exported thus to be implanted with the name
      import * wsc # re-export the exports
    }

    {

      go {
        clnt = Client(
          this.forager.negoModu, this.addr,
          init=method _ () {
            import * nego'arts into that
          },
        )
        case clnt.addrs() of { addr =>_ } ->
        console.debug<| 'Connected to worksource at: ' ++ addr
        case clnt.eol() of {
          false -> { pass }
          clnt.join() # this normally throws
          error( 'connection to worksource failed' )
        }

        # stop this wsc anyway the network connection is disconnected
        clnt.join() @=> this.stop()
      }

      # register this wsc
      this.forager.wsd[ this.key() ] = this

    } $=> { exc } -> { # this catches exceptions occurred directly or
      # in forked threads
      console.error<| 'Stopping team ' ++this++ ' on error: ' ++ desc( exc )
      this.stop()
    }

    return this.hcReserved
  }

  # this method meant to be forked once per wsc
  method teamKeeper() {
    # terminate this thread on stop signal
    perceive this.stopped { break }

    rfn = mre( this.reformNumber )

    # track delta of employment
    hcEmployed = 0
    go for hcConfirmed from this.hcEmployed do {
      if hcConfirmed > this.hcReserved then error (
        'Worksource ' ++ this.addr ' confirming ' ++ hcConfirmed
        ++ ' while only ' ++ this.hcReserved ++ ' reserved.'
      )
      console.debug<| 'Worksource ' ++ this.addr ++ ' confirmed '
      ++ hcConfirmed ++ ' heads employed.'
      # TODO any deal with the delta ?
      hcEmployed = hcConfirmed
      ai { # request reform
        this.reformNumber <- mre( this.reformNumber ) + 1
      }
    }

    # do reform upon appropriate chances
    while true {
      # wait next chance to reform
      for rfn' from this.reformNumber do {
        rfn' != rfn -> { rfn = rfn' break }
      }
      # keep enough worker processes running
      while this.workers.size < hcEmployed {
        case wscStartWorker(
          this.addr,
          this.workDir, this.executable, this.workModu,
        ) of { wkrPid } -> {
          this.workers[ wkrPid ] = this
          this.forager.workerStarted <- ( wkrPid, this )
        }
      }
    }
  }

  method stop() {
    this.hcEmployed <- nil
    this.stopped <- true

    # forcefully stop all workers for this worksource
    for ( pid, _ ) from this.workers do {
      # make sure this worker process is killed
      killWorker( pid )
      this.workers[ pid ] = nil # forget about it
    }

    # check unleash heads reserved for this worksource
    ai if this.hcReserved > 0 then {
      this.forager.hcIdle <- this.hcReserved
      this.hcReserved = 0
    }
    # forget about this worksource
    ai case this.forager.wsd[ this.key() ] of this -> {
      this.forager.wsd[ this.key() ] = nil
    }
  }

  method update (
    hcPlanned, executable, workDir, workModu, priority,
  ) {
    # TODO check and deal with expected / unexpected changes
    this.hcPlanned = hcPlanned
    this.executable = executable
    this.workDir = workDir
    this.workModu = workModu
    this.priority = priority
  }

}


export class Forager {

  method __init__(
    headcount as this.headcount,
    negoModu as this.negoModu = 'swarm/negotiator',
  ) {
    this.headcount >= 1 |> error( 'Invalid headcount: ' ++this.headcount )

    # prioritized recent queue for backlog of worksources
    this.wsq = PRQ()
    # worksources currently being actively worked on
    this.wsd = {}

    # available headcounts to be offered
    this.hcIdle = sink
    # stream of `pid:wsc` for ever started worker processes
    this.workerStarted = sink
  }

  # A work source (e.g. a head hunter) should announce call-for-workers
  # in this format, and this intends to be exposed (imported) by a network
  # facing entry module of the sniffer, so as to react to cfws
  export method WorkToDo (
    hcPlanned, # planned headcount to recruit
    executable, # executable file path to launch as worker processes
    workDir, # working directory
    workModu, # work definition module
    priority = 0, # used to prioritize allocation of work heads
  ) {
    # apply any filter in effect
    # todo only filtering by work modu so far, elaborate in the future
    if perform ignoreWorkModu( workModu ) then return nil

    # we are supposed to connect to the source address of the announced
    # call-for-workers (UDP packet), to comm with the announcing worksource
    #
    # and the sniffer (initiated for this forager) should be providing the
    # effectful `sourceAddr`
    cfwAddr = perform sourceAddr

    # such addr objects are non-equal from eachother in object semantics,
    # even from the same advertiser, so we use its repr str as identifier
    wsKey = repr( cfwAddr )
    ai {
      case this.wsd[ wsKey ] of {
        { _ } -> { pass } # already been worked on TODO update info ?
        case this.wsq.iqd[ wsKey ] of {
          { wsc } -> {
            # already in queue, refresh its known states up-to-date
            wsc.update( hcPlanned, executable, workDir, workModu, priority, )
          }
          this.wsq.enque( WSC (
              forager=this, addr=cfwAddr,
              hcPlanned, executable, workDir, workModu, priority,
          ) )
        }
      }
    }

    return nil
  }

  method scheduleTeams() {

    # maintain mapping from pid of live worker processes to its team manager
    workers = {}
    go for ( wkrPid, wsc ) from this.workerStarted do workers[ wkrPid ] = wsc

    # track done of worker processes
    go for (*** _ ) from this.workerStarted do case waitAnyWorkerDone()
    of { donePid:doneAct:doneDesc } -> {
      console.debug<| 'Swarm worker pid=' ++ donePid ++ ' ' ++ doneAct
      ++ ' - ' ++ doneDesc
      case workers[ donePid ] of { doneWSC } -> { ai {
          # uncount this one from the team's number of working heads
          doneWSC.workers[ donePid ] = nil
          # request reform of the team
          doneWSC.reformNumber <- mre( doneWSC.reformNumber ) + 1
          workers[ donePid ] = nil # forget about it
      } }
    }

    # start out to have the configured total headcount available
    hcCum = this.headcount nsLastIdle = 0
    # collect idle heads in a dedicated thread, to not miss any unleash
    go for hcNewIdle from this.hcIdle do {
      if hcNewIdle < 1 then { continue }
      nsLastIdle = console.now()
      hcCum += hcNewIdle
    }
    # insert some zero idle counts periodicly, so the check in following loop
    # won't dead wait in case it can only partial fill for a long time
    go for _ from console.everySeconds( 1 ) do this.hcIdle <- 0

    # engage with next worksource in the queue of discovery
    for wsc from this.wsq.streamOut() do {
      console.debug<| 'Discovered new worksource: ' ++ wsc.addr

      # do wait if can not immediately fulfill all the heads
      if hcCum < this.headcount && hcCum < wsc.hcPlanned
      then for _ from this.hcIdle
      # can fulfill now
      do ( hcCum >= wsc.hcPlanned || hcCum >= this.headcount )
      # or waited long enough while partial filling is possible
      # TODO make the hardcoded 5 seconds tunable
      || ( hcCum > 0 && console.now() - nsLastIdle > 5e9 )
      -> { break }

      console.debug<| 'Engaging worksource ' ++ wsc ++ ' with '
      ++ hcCum ++ ' heads to offer.'

      # engage with this worksource with as many free heads atm
      # `engage()` should return quickly without waiting for network,
      # network operations are actually forbidden by the intrinsic tx of
      # assignment
      hcCum -= wsc.engage( hcCum )
    }

  }

}
