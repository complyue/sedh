
# Worksource Queue implementation


{#
 # Prioritized Recent Queue
 #
 # priority first, then first in first out at same priority;
 # but may be pushed out of queue, by same priority, after a
 # while if many new comes.
 #
 # Parameters
 # ==========
 # 	* lingers - the least seconds a task should be kept in queue.
 # 	* backlog - the max number of records should be kept in queue.
 #
 # Implications
 # ============
 # 	* new records can push old records out of queue, those lingered
 # 	  more time than `lingers`.
 # 	* new records will be dropped if the queue is full of lingering
 # 	  records, wrt `backlog`.
 #
 # Starvation Preventation
 # =======================
 # 	* a worksource should repeat announcing call-for-workers after
 # 	  `lingers` seconds if it's still not fulfilled then.
 # 	* fast repetitions from same worksource within `lingers` seconds
 # 	  should not get duplicated records created, and should neither
 # 	  get the existing task's enqueue time updated, for other
 # 	  worksource's sake of fireness.
 #
 # Note
 # ====
 # 	this implementation assumes that there're not too many priority
 # 	levels, or it'll perform rather inefficiently.
 #}
class PRQ {

  method __init__(
    # the lease seconds a task should be kept in queue
    lingers as this.lingers,

    # the max number of records should be kept in queue
    backlog as this.backlog,
  ) pass

  # mapping addr key to worksources those in queue
  iqd = {}
  # list of CRQs sorted by priority
  pl = []


  # queue change number, ever increasing as each new ws enqueued
  qcn = sink
  qcn <- 0  # initialize to 0

  generator streamOut() while true {
    ai {
      case this.pl of {
        { crq => rest'pl } -> case crq.popLeft() of {
          {( wsc, _qt )} -> {
            if crq.length() < 1  # no more record at this priority
            then this.pl = rest'pl  # forget this crq
          }
          error('bug: empty CRQ in PRQ')
        }
        # empty PRQ
        wsc = None
        seen'qcn = mre(this.qcn)
      }
    }
    if wsc != None then {
      yield wsc  # engagement with this worksource expected
      continue
    }
    for qcn from this.qcn do  # wait until queue changed
      qcn != seen'qcn -> { break }
  }

  method enque(wsc) ai {
    crq = this.crq(wsc.priority)
    if crq.pushLeft(wsc) then {
      this.iqd[wsc.key()] = wsc
      # increase & post queue change number
      this.qcn <- case mre(this.qcn) of { qcn } ->
        # do with some wrapback, don't grow the number too big
        if qcn >= 1e6 then 1 else qcn+1
    }
  }

  method crq(priority) ai {
    higher = []
    lower = this.pl
    while true case lower of {
      { crq => rest'pl } -> {
        # already has a crq for this priority
        if priority == crq.priority then return crq
        if priority  > crq.priority then {
          # found the insert position for this priority
          crq = CRQ(this, priority)
          this.pl = higher >> (crq => lower)
          return crq
        }
        # priority is lower
        crq => higher
        lower = rest'pl
      }
      # create a crq with lowest priority
      crq = CRQ(this, priority)
      this.pl = higher >> (crq => lower)
      return crq
    }
  }

}


{#
 # Capped Recent Queue
 #}
class CRQ {

  # queue of worksources and their respective enque time,
  # each record being a tuple
  extends Deque()

  method __init__(
    prq as this.prq,
    priority as this.priority,
  ) pass

  # return a bool indicating whether successfully enqueued or not
  method enque(wsc) ai {
    wsc.priority == this.priority |> error('bug: priority mismatch')
    lingerThres = console.now() - this.lingers * 1e9

    while this.length() > 0 case this.peekRight() of {( _wsc, qt )} -> {
      if qt > lingerThres then { break }
      this.popRight()
    }
    if this.length() >= this.prq.backlog then
      return false  # queue still full
    
    this.pushLeft( (wsc, now) )
    return true
  }

}

