# Worksource Queue implementation

{#
 # Prioritized Recent Queue
 #
 # priority first, then first in first out at same priority;
 # but may be pushed out of queue, by same priority, after a
 # while if many new comes.
 #
 # Parameters
 # ==========
 # 	* lingers - the least seconds a task should be kept in queue.
 # 	* backlog - the max number of records should be kept in queue.
 #
 # Implications
 # ============
 # 	* new records can push old records out of queue, those lingered
 # 	  more time than `lingers`.
 # 	* new records will be dropped if the queue is full of lingering
 # 	  records, wrt `backlog`.
 #
 # Starvation Preventation
 # =======================
 # 	* a worksource should repeat announcing call-for-workers after
 # 	  `lingers` seconds if it's still not fulfilled then.
 # 	* fast repetitions from same worksource within `lingers` seconds
 # 	  should not get duplicated records created, and should neither
 # 	  get the existing task's enqueue time updated, for other
 # 	  worksource's sake of fireness.
 #
 # Note
 # ====
 # 	this implementation assumes that there're not too many priority
 # 	levels, or it'll perform rather inefficiently.
 #}
export class PRQ {

  method __init__(
    # the lease seconds a task should be kept in queue
    lingers as this.lingers = 5*60, # 5 minutes by default
    # the max number of records should be kept in queue
    backlog as this.backlog = 50, # 50 by default
  ) {
    # mapping addr key to worksources those in queue
    this.iqd = {}
    # list of CRQs sorted by priority
    this.pv = []

    # queue change signal
    this.qcSignal = sink?subseq
  }

  generator streamOut() while true {
    ai {
      case this.pv of {
        { pcrq :> rest'pv } -> case pcrq of { ( _priority, crq ) }
        -> case crq.deq() of {
          { wsc } -> if crq.empty() then {
            # no more record at this priority
            this.pv = rest'pv # forget this crq
          }
          error( 'bug: empty CRQ in PRQ' )
        }
        # empty PRQ
        wsc = None
      }
    }
    if wsc is not None then {
      yield wsc # engagement with this worksource expected
      continue
    }
    # wait until queue changed
    for () from this.qcSignal do break
  }

  method enque( wsc ) ai {
    crq = this.crq( wsc.priority )
    crq.enq( wsc ) -> {
      this.iqd[ wsc.key() ] = wsc
      # signal the queue changed
      this.qcSignal <- ()
    }
    console.warn<| 'Worksource backlog queue full, dropping ' ++ wsc
  }

  method crq( priority ) ai {
    higher = []
    lower = this.pv
    while true case lower of {
      { r :> rest'pv } -> case r of { ( p, crq ) } -> {
        # already has a crq for this priority
        if priority == p then return crq
        # found the insert position for this priority
        if priority > p then {
          crq = CRQ( this )
          this.pv = higher /> ( ( priority, crq ) :> lower )
          return crq
        }
        # priority is lower
        r :> higher
        lower = rest'pv
      }
      # create a crq with lowest priority
      crq = CRQ( this )
      this.pv = higher /> ( ( priority, crq ) :> lower )
      return crq
    }
  }

}


{#
 # Capped Recent Queue
 #
 # a queue of constant capacity specified at construction
 #
 # enq() returns false when queue is full of lingering ws
 # deq() returns nil when no item in queue
 #}
class CRQ {

  method __init__ ( prq as this.prq ) {
    # queue of worksources and their respective enque time,
    # each record being a tuple
    #
    # Note Vector is non-transactional container, correctness under
    # concurrency must be guaranteed by carefully manipulation of
    # rp/wp wrt STM semantics
    this.l = Vector( length=this.prq.backlog )

    this.rp = -1
    this.wp = 0
  }

  method empty() this.rp < 0

  method full() this.rp is this.wp

  # return a bool indicating whether successfully enqueued or not
  method enq( wsc ) ai {
    t = console.now()
    lingerThres = t - this.prq.lingers * 1e9

    qfull = this.wp is this.rp
    if qfull then {
      let ( wsc', qt ) = this.l[ this.rp ]
      # queue full of lingering wsc
      if qt > lingerThres then return false
      # pushed out of queue
      this.prq.iqd[ wsc'.key() ] = nil
    }
    this.l[ this.wp ] = ( wsc, t )
    this.prq.iqd[ wsc.key() ] = wsc
    # previously empty
    if this.rp < 0 then this.rp = this.wp
    this.wp += 1 # move the write pointer
    if this.wp >= len( this.l ) then this.wp = 0
    if qfull then this.rp = this.wp

    return true
  }

  # return nil when queue is empty, or the next eligible worksource is popped
  # out and returned
  method deq() while true ai {
    # queue empty
    if this.rp < 0 then return nil
    case this.l[ this.rp ] of {
      { ( wsc, _qt ) } -> this.l[ this.rp ] = nil
      # dirty read, this is possible as Vector is non-transactional container
      continue
    }
    this.rp += 1
    if this.rp >= len( this.l ) then this.rp = 0
    # drained
    if this.rp is this.wp then { this.rp = -1 this.wp = 0 }
    # forget about it
    this.prq.iqd[ wsc.key() ] = nil
    return wsc
  }

}
