
import * 'net'

import * 'swarm/RT'
import * 'swarm/symbols'


# work definition scripts are allowed to change the inferred
# configuration at 'swarm/ENV', import it as a namespace to
# always use up-to-date artifacts living there
case import (** _ ) 'swarm/ENV' of { senv } -> { pass }


export class HeadHunter {

  # fetch effective configurations, cache as instance attribute
  priority = perform priority
  headcount = perform headcount

  class Forager {
    hcEmployed = 0
    hcWorking = 0
    method __init__(
      peer as this.peer, pid as this.pid, maxHC as this.maxHC,
    ) pass
  }

  class Worker {
    method __init__(
      peer as this.peer,
      workerPid as this.pid,
      foragerPid as this.manager,
    ) {
      errSink = this.peer.armChannel( errChan )
      # convert disconnection without result to error
      go {
        discExc = None
        this.peer.join() $=> {
          { discExc } -> { pass }
        }
        errSink <- discExc |> PeerError( 'Swarm worker disconnected' )
      }
    }

    method __repr__() {
      '<Worker pid=' ++ this.pid ++ ' via ' ++ this.peer.ident() ++ '>'
    }
  }

  hcEmployed = 0 # total heads employed by this HH

  # a swarm node connection identifying itself as a forager
  method OfferHeads(
    foragerPid, maxHC,
  ) {
    ai { # calculate number of employment atomically
      hcDemand = this.headcount - this.hcEmployed
      hcToEmploy = min( maxHC, hcDemand )
    }
    hcToEmploy < 1 -> { # no demand, disconnect
      # todo send zero employment ?
      that.peer.stop()
    }

    # employ heads from this forager
    ai case this.foragers[ that.peer ] of {
      nil -> {
        forager = Forager(
          that.peer, foragerPid, maxHC,
        )
        this.foragers[ that.peer ] = forager
      }
      { forager } -> {
        # update max headcount it is able to provide
        forager.maxHC = maxHC
      }
    }
    # todo could this possibily exceed its maxHC ?
    forager.hcEmployed += hcToEmploy
    console.debug<| 'HH is hiring ' ++ forager.hcEmployed ++ ' heads from '
    ++ that.peer.ident() ++ ' now.'
    that.peer.p2c( dataChan, repr( forager.hcEmployed ) )

    return nil
  }

  # a swarm node connection identifying itself as a worker
  method StartWorking(
    workerPid, foragerPid,
  ) {
    console.debug<| 'Worker process pid=' ++ workerPid ++ ' managed by '
    ++ foragerPid ++ ' via ' ++ that.peer.ident() ++ ' start working.'
    worker = Worker( that.peer, workerPid, foragerPid )
    this.idleWorkers.push( worker )
    this.workerAvailable <- worker
    return nil
  }

  method __swarm_conn_init__() {
    that.OfferHeads = this.OfferHeads
    that.StartWorking = this.StartWorking
  }

  case Server (
    'swarm/headhunter', # the service module
    perform swarmIface $=> '0.0.0.0', # local addr to bind
    0, # local port to bind
    # per-connection peer module initialization
    init=__swarm_conn_init__,
  ) of { server } -> {
    case server.addrs() of {
      { wsAddr =>_ } -> console.info<| 'HeadHunter listening: ' ++ wsAddr
      # or the network has failed, propagate the error
      server.join() # this usually throws
      # in case join() didn't throw, report this error
      error( 'HeadHunter failed listening.' )
    }
  }

  # call-for-workers advertiser
  case Advertiser(
    # target swarm address
    perform swarmAddr $=> '127.0.0.1', perform swarmPort $=> 3722,
    # announce call-for-workers from our worksource addr
    fromAddr=wsAddr,
  ) of { cfw } -> { pass }

  # data structures for job scheduling
  foragers = {}
  workerAvailable = sink # signal on new worker available,
  # but should obtain an available worker from idleWorkers with tx
  idleWorkers = [] # FILO queue
  pendingJobs = [] # FILO queue
  pendingCntr = sink # increased/decreased on job submit/result/err
  finishingUp = sink # signal of no more jobs, i.e. to start finishing up
  finished = sink # the final singal that all have finished

  method allFinished() {
    finished = # note this has an implicit tx which is desirable here
    mre( this.finishingUp ) == true
    && mre( this.pendingCntr ) == 0
    && null( this.pendingJobs )
    ; | finished -> this.finished <- true
    return false
  }

  method __init__( resultSink as this.resultSink ) go {
    # stop immediately on the last signal that all have finished
    perceive this.finishingUp {
      this.allFinished() -> { break }
    }
    perceive this.pendingCntr 0 -> {
      this.allFinished() -> { break }
    }

    # advertise call-for-workers when there's demand
    for _ from console.everySeconds(
      perform cfwInterval $=> 3, # use effectful config
      wait1st=false, # announce the first CFW immediately
    ) do {
      # check if all have finished
      this.allFinished() -> { break }

      # calibrate this.hcEmployed, wrt forager disconnection etc.
      hcEmployed = 0
      for ( peer, forager ) from this.foragers do {
        if false != peer.eol() then {
          this.foragers[ peer ] = nil # forget about it
        }
        hcEmployed += forager.hcEmployed
      }
      if this.hcEmployed != hcEmployed then {
        console.debug<| 'HH has ' ++ hcEmployed ++ ' heads employed now.'
        this.hcEmployed = hcEmployed
      }

      hcDemand = this.headcount - hcEmployed
      if hcDemand > 0 then {
        console.debug<| 'Calling ' ++ hcDemand ++ ' workers from '
        ++ cfw.addrs()
        cfw.post( expr

          WorkToDo(
            {$ hcDemand $},
            {$ senv.jobExecutable $},
            {$ senv.jobWorkDir $},
            {$ senv.jobWorkModu $},
            {$ priority $},
          )

        )
      }
    }
  }

  method trackJob( worker, ips ) {
    # arm new private data/err channels to this job
    jobSink = worker.peer.armChannel( dataChan )
    # perform retry effect on error
    perceive worker.peer.armedChannel( errChan ) { jobExc } -> {
      worker.peer.stop() # disconnect this worker anyway on error

      # call the effectful failure callback
      case perform @shouldRetryJob of {
        false -> { pass }
        true -> this.pendingJobs.push( ips )
        { retryChk } -> case retryChk( jobExc, ips ) of { newIPS } -> {
          this.pendingJobs.push( newIPS )
        }
      }

      # failed to get a result, but we know it's not pending now
      if nil == mre( jobSink ) then {
        this.pendingCntr <- mre( this.pendingCntr ) - 1
        jobSink <- nil
      }

      break # terminate this thread
    }
    # submit ips and process result
    producer submitJob( outlet ) {
      worker.peer.p2c( dataChan, repr( ips ) )
    }
    for (*** result ) from submitJob( outlet=jobSink ) do {
      this.resultSink <- ( ips, result )
      this.pendingCntr <- mre( this.pendingCntr ) - 1
      this.idleWorkers.push( worker )
      this.workerAvailable <- worker
      break # one ips at a time
    }
  }

  method submitJobs() {
    while true {
      ips = this.pendingJobs.pop()
      ips == None -> { return nil } # no more pending jobs
      this.pendingCntr <- 1 + ( mre( this.pendingCntr ) |> 0 )

      while true {
        # try grab a present idle worker and assign it this job
        worker = this.idleWorkers.pop()
        worker != None -> {
          console.debug<| 'Job assigned to ' ++ worker ++ ' - ' ++ ips
          # start asynchronous concurrency
          go trackJob( worker, ips )
          break # this job settled, proceed to next job
        }

        # no immediate idle worker, need to wait
        console.debug<| 'Wait for idle workers.'
        # wait until new idle workers appear
        for _ from this.workerAvailable do {
          not null( this.idleWorkers ) -> { break }
        }
        console.debug<| 'Got idle workers.'
      }
    }
  }

  method dispatchJob( ips ) {
    this.pendingJobs.push( ips )
    this.submitJobs()
  }

  method finishUp() {
    this.finishingUp <- true
    not this.allFinished() ->
    for _ from this.finished do { break }
  }

}
