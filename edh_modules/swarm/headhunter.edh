
import * 'net'

import * 'swarm/RT'

# work definition scripts are allowed to change the inferred
# configuration at 'swarm/ENV', import it as a namespace to
# always use up-to-date artifacts living there
case { import (**_) 'swarm/ENV' } of { senv } -> { pass }


export class HeadHunter {

  # fetch effective configurations, cache as instance attribute
  priority = perform priority
  headcount = perform headcount

  class Forager {
    hcEmployed = None
    hcWorking = 0
    method __init__(
      peer as this.peer, pid as this.pid,
      maxHC as this.maxHC,
    ) pass
  }

  class Worker {
    method __init__(peer as this.peer) {
      this.datas = perform @dataSink
    }
  }

  # a swarm node connection identifying itself as a forager
  method OfferHeads(
    foragerPid, maxHC, 
  ) {
    ai {  # calculate number of employment atomically
      hcDemand = this.headcount - this.hcEmployed
      hcToEmploy = min(maxHC, hcDemand)
      if hcToEmploy >= 1
        then this.hcEmployed += hcToEmploy
    }
    hcToEmploy < 1 -> {  # no demand, disconnect
      # todo send zero employment ?
      that.peer.stop()
    }
    # employ heads from this forager
    ai case this.foragers[that.peer] of {
      nil -> this.foragers[that.peer] = (forager = Forager(
        that.peer, foragerPid, maxHC,
      ))
      { forager } -> {
        # update max headcount it is able to provide
        forager.maxHC = maxHC
      }
    }
    that.peer.p2c(dataChan, repr(
      # todo could this possibily exceed its maxHC ?
      forager.hcEmployed += hcToEmploy
    ))
  }

  # a swarm node connection identifying itself as a worker
  method StartWorking(
    workerPid, foragerPid,
  ) {
    this.workerAvailable <- Worker(that.peer) => this.idleWorkers
  }

  method __swarm_conn_init__() {
    that.OfferHeads = this.OfferHeads
    that.StartWorking = this.StartWorking
  }

  case Server (
    'swarm/headhunter',  # the service module
    '0.0.0.0',           # local addr to bind
    0,                   # local port to bind
    # per-connection peer module initialization
    init=__swarm_conn_init__,
  ) of { server } -> {
    case server.addrs() of {
      { wsAddr =>_ } -> console.info<| 'HeadHunter listening: ' ++ wsAddr
      # or the network has failed, propagate the error
      server.join()  # this usually throws
      # in case join() didn't throw, report this error
      error('HeadHunter failed listening.')
    }
  }

  # call-for-workers advertiser
  case Advertiser(
    # target swarm address
    perform swarmAddr, perform swarmPort,
    # announce call-for-workers from our worksource addr
    fromAddr=wsAddr,
  ) of { cfw } -> { pass }

  # data structures for job scheduling
  hcEmployed = 0
  foragers = {}
  workerAvailable = sink
  idleWorkers = []
  pendingJobs = []

  method __init__( resultSink as this.resultSink ) pass

  method trackJob(worker, ips) {
    # arm new private data/err channels to this job
    dataSink = worker.peer.armChannel(dataChan)
    errSink = worker.peer.armChannel(errChan)
    # convert disconnection without result to error
    go {
      worker.peer.join() $=> {
        { discExc } -> { pass }
        discExc = None
      }
      case mre(dataSink) of nil ->
      errSink <- discExc |>
        PeerError('Swarm worker disconnected unexpectedly')
    }
    # perform retry effect on error
    perceive errSink { jobExc } -> {
      # mark local data chan eos, for there's an stm dead lock to avoid,
      # due to the for loop
      dataSink <- nil

      worker.peer.stop() # disconnect on error

      case perform @shouldRetryJob of {
        false -> { pass }
        true -> ips => this.pendingJobs
        { retryChk } -> case retryChk( jobExc, ips ) of { newIPS } -> {
          newIPS => this.pendingJobs
        }
      }
      break  # terminate this thread
    }
    # submit ips and process result
    producer submitJob(outlet) {
      worker.peer.p2c(dataChan, repr(ips))
    }
    for result from submitJob(outlet=dataSink) do {
      this.resultSink <- (ips, result)
      this.workerAvailable <- worker => this.idleWorkers
      break  # one ips at a time
    }
  }

  method submitJobs() {
    while true {
      ai case this.pendingJobs of {
        { ips => pendingJobs } ->
          this.pendingJobs = pendingJobs
        return nil  # no more pending jobs
      }

      while true {
        ai case this.idleWorkers of {
          { worker => idleWorkers} ->
            this.idleWorkers = idleWorkers
          worker = None
        }
        worker != None -> {
          # start asynchronous concurrency
          go trackJob(worker, ips)
        }

        # calibrate this.hcEmployed, wrt forager disconnection etc.
        hcEmployed = 0
        for (peer, forager) from this.foragers do {
          if false != peer.eol() then {
            this.foragers[peer] = nil  # forget it
          }
          hcEmployed += forager.hcEmployed
        }
        this.hcEmployed = hcEmployed

        # advertise call-for-workers if there's demand
        if (hcDemand = this.headcount - this.hcEmployed) > 0
        then cfw.post(expr

WorkToDo(
  {$ hcDemand $},
  {$ senv.jobExecutable $},
  {$ senv.jobWorkDir $},
  {$ priority $},
)

          )
        # wait until new idle workers appear
        for _ from this.workerAvailable do
        if not null(this.idleWorkers) then { break }
      }
    }
  }

  method dispatchJob(ips) {
    ips => this.pendingJobs
    this.submitJobs()
  }

}
