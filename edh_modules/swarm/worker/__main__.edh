#
# Swarm batch worker process entry module
#

import * 'net'

import * 'swarm/symbols'
import * 'swarm/RT'

# work definition scripts are allowed to change the inferred
# configuration at 'swarm/ENV', import it as a namespace to
# always use up-to-date artifacts living there
case { import (**_) 'swarm/ENV' } of { senv } -> { pass }


# take the worksource connection file describer, make it a peer for comm
# note `wscTake()` performs IO, so assign its return value won't work
case wscTake(senv.wscFd, Peer()) of { peer } -> { pass }


# inherit the work module, so we have access to `@doOneJob` implemented there
extends {
  import (**_) senv.jobWorkModu
}


dataSink = peer.armChannel(dataChan)

effect {
  ;@netPeer = peer
  ;@dataSink = dataSink
}


# identify this connection as swarm worker to the headhunter, then it will
# start sending ips to our data channel
producer initiateJobs(outlet) {
  peer.postCommand(expr

StartWorking({$ senv.swarmWorkerPid $}, {$ senv.swarmManagerPid $})

  )
}

# apks are expected to be posted to a worker's data channel, one by one
go for ips from initiateJobs( outlet=dataSink ) do {

  console.debug<| 'Computing ips: ' ++ ips

  case this.@doOneJob(***ips) of {
    { result } -> {
      peer.p2c(dataChan, repr(result))
    }
    throw UsageError('Swarm job returned no result', ips=ips)
  } $=> { jobExc } -> {
    console.error<| 'Swarm job [' ++ senv.jobWorkModu ++ ' - ' 
      ++ senv.swarmManagerPid ++ '>' ++ senv.swarmWorkerPid ++ '] failure:\n'
      ++ jobExc
    peer.p2c(errChan, repr(jobExc))
    break  # stop processing more jobs
  }

}


{

  while false == peer.eol() case peer.readCommand() of {
    # note a command resulting in nil is ignored here
    { cmdVal } -> {
      console.warn<| 'Unexpected cmd from ' ++ peer ++ '\n  ' ++ cmdVal
      cmdVal = nil  # clear it
    }
  }

} @=> {
  { exc } -> {
    console.error<| 'Disconnecting worker from worksource ' ++ peer
      ++ ' for error: ' ++ exc
  }
  console.debug<| 'Disconnecting worker from worksource ' ++ peer
}
